---
layout: post
title:  "Grappling with Go"
date:   
author: ESR
---
In a previous blog post, I observed that one of the medium-term
possibilities we're seriously considering for NTPsec is moving the
entire codebase out of C.  I continued that the two languages we're
looking at hard are Rust and Go.  Then, in another blog post, I
revealed the existence of a Go port of David Wheeler's slloccount
tool.

In this post I'm going to get a bit deeper into Go, loccount, my
learning experience with the language, and Go's potential suitability
for what we're doing at NTPsec.

Toy programs - conscious finger exercises - are a terrible way to
learn a new language. They're boring, and they don't make you think
enough.  For me, tutorials stuffed with pretty, bite-sized examples
don't work well either - I feel like I'm being patronized by the
authors, fed with excessively-safe bonbons when what I want to
do is joyously tear off and bolt huge chunks of meat.

What does work for me is diving in - tackling a real problem
of the right size, with a reference manual for the language to hand in
a browser window.

The right size of problem can't be too small, because if it is you
don't engage enough of the language to really learn it.  Nor can it be
so large that you're it risk of getting lost in the problem itself, rather
than staying at least half focused on exploring the implementation strategies
that the language affords.  In the ideal case, your right-sized problem is
one you're strongly motivated to solve independenrly of your desire to
learn the language.

I was fortunate. I found an NTPsec-related problem that hit the sweet
spot almost exactly.  Later I'll explain why it might have been just a
tiny bit too small, but in retrospect it still isn't clear how I could
have chosen any better in advance.  I'm happy with the outcome.

One of the central thrusts of our strategy is removing code from the
ancestral NTP Classic codebase without breaking function.  One of the
main themes in the story we tell the world about what we're doing is
how much code we've removed.  We measure our success that way. So a
tool I have used a lot is David A. Wheeler's
http://www.dwheeler.com/sloccount/[sloccount].

It's a good tool, but it has some minor annoying flaws.  The largest
of these is that, in my opinion, the output is excessively verbose.  I
don't like programs that eat your screen space with unnecessary
progress messages, license announcements, author credits, copyrights,
and other impedimenta and _doesn't give you any way to shut that off._
I'm also not usually interested on the cost-modeling feature.

A second problem is that it's slow.  It has to rely on MD5 caching of
repeated counts to have acceptable performance at all.  And it's slow
because internally it's a pile of Perl, shell scripts, and C helper
code that David himself concedes is rather a mess.  Thus makes it
difficult to modify, so de-verbosifying and speeding it up is not
very practical.

Problem: write a sloccount replacement in Go. It took me about four
days of fairly steady thinking and work to get to a version that could
replace sloccount for NTPsec's needs, then another ten days of occasional
tweaking while I worked on other project issues.  You can browse the
result https://gitlab.com/esr/loccount[on GitLab].

The result is quite fast compared to sloccount, like a 4x to
10x speedup on the typical case. Speedup is inversely proportional to
codebase size, which just tells us that both sloccount and loccount
are dominated by I/O costs that increase as a fraction of runtime with
code volume.  Notably, however, this speed is *without* the
complicated caching/memoization that sloccount uses; if you run without
that the difference gets quite a bit larger.

I also took the opportunity to add recognizers and totalizers for a
bunch of new languages, because who wouldn't? I discovered that if all
you care about is comment and string syntax, almost all computer
languages fall into five groups: C-like, scripting, generic, Pascal-like,
and Fortran-like. It's not too difficult to write generic parsers for
these groups and keep most of the language-specific information in
a handful of large tables.  Thus, loccount is also dramatically easier
to extend.

Now to Go itself.  I'll admit I was a little apprehensive going in.
The culture around Go smells of hypernormativeness - you're going to
program the way Rob Pike and his buddies think is right conduct, and
if you don't like that you can hit the highway, Jack.  There's also
been a lot of talk about Go's alleged refusal to incorporate design
ideas from recent languages; one
https://github.com/ksimka/go-is-not-good[aggregation site of Go
criticism] tags this the "stuck in 70s" problem.

Thankfully, my fears went largely unrealized.  The rhetoric around the
language may be rather truculent, but there's more room to stretch in
it than I expected. Pike's taste is austere but mostly pretty
good. And "stuck in 70s" is unfair in at least one major respect: the
language includes first-class map objects (almost equivalent to Python
dictionaries) which Perl pioneered in the 1980s.

One half-forgotten 1970s concept I'm glad Go revived is
channels. I've had a strong feeling Tony Hoare was onto something
seriously good ever since reading about occam's implementation of his
Communicating Sequential Processes model back in the 80s. It's nice to
see them in a language I can use for production, and very gratifying
to find that they really are an effective tool for carving
up concurrency problems.

I checked this by writing loccount as a parallized tree traversal.  Each
file in the tree gets a goroutine spawned to count its lines; the threads
run in parallel and as each finishes its work it stuffs a statistics block
into a channel. The main thread blocks on the output end, reading each
statistics block as it becomes available and saving it for report
generation.

The resulting code is really simple and natural.  The channel is the
only symchronization mechanism and its thread-safe queue behavior is
easy to reason about.  If there is one pitch the Go designers have
knocked right out of the park, this is it.  I'm already sure I'm
going to miss it a lot in Rust.

Some things I thought I'd dislike that rapidly turned into non-issues:
visibility by variable case, odd required syntax of blocks and
conditional chains, absence of operator overloading.

The language does have annoyances. The absence of const is a minor
one.  Go binaries are statically linked to a copy of its runtime; thus
they are annoyingly fat.  $GOPATH is a pain, and the style of project
layout the build system wants you to use is ugly to my eyes.  No
ternary operator.  There are no map/reduce/filter primitives.

Go has a surprisingly strong flavor of Python for a compiled language,
which I think shows that the designers were paying attention to the
right things.  On the other hand, the single feature I find most
conspicuous by its absence is Python-style try/catch with class-valued
exceptions (and the related idioms around context managers and Python
"with").

I'm aware of all the arguments against nonlocal jumps, but this is
still a near-showstopper for readily translating code out of Python into Go;
too many Python idioms will break and have to be translated in complicated
and failure-prone ways. Someday this could be a problem for NTPsec; if we
move to Go we'll probably want to go that whole way.

My learning project may have been just a little too small, as it gave
me no reason to dive into the stranger corners of the Go object system. I
haven't fully learned interfaces and reflection yet, so I can't speak to
any design deficencies thzt might lurk there.

Now let's return to more specific NTPsec-related concerns.  What speifically
can we say about Go's suitability as an implementation labguage for ntpd?

The big foreground issue is garbage collection.




// end
